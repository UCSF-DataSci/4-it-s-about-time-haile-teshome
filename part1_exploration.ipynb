{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Data Exploration and Preprocessing\n",
    "\n",
    "In this notebook, you will implement functions to load, preprocess, and visualize physiological data from the Wearable Exam Stress Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/318xx77d4wbb95s3dsdtsshc0000gq/T/ipykernel_65500/3702442187.py:11: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn')\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "Implement the `load_data` function to read and organize the physiological data from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: S5 - Final\n",
      "Loaded: S5 - Midterm 1\n",
      "Loaded: S5 - Midterm 2\n",
      "Loaded: S2 - Final\n",
      "Loaded: S2 - Midterm 1\n",
      "Loaded: S2 - Midterm 2\n",
      "Loaded: S3 - Final\n",
      "Loaded: S3 - Midterm 1\n",
      "Loaded: S3 - Midterm 2\n",
      "Loaded: S4 - Final\n",
      "Loaded: S4 - Midterm 1\n",
      "Loaded: S4 - Midterm 2\n",
      "Loaded: S10 - Final\n",
      "Loaded: S10 - Midterm 1\n",
      "Loaded: S10 - Midterm 2\n",
      "Loaded: S8 - Final\n",
      "Loaded: S8 - Midterm 1\n",
      "Loaded: S8 - Midterm 2\n",
      "Loaded: S1 - Final\n",
      "Loaded: S1 - Midterm 1\n",
      "Loaded: S1 - Midterm 2\n",
      "Loaded: S6 - Final\n",
      "Loaded: S6 - Midterm 1\n",
      "Loaded: S6 - Midterm 2\n",
      "Loaded: S7 - Final\n",
      "Loaded: S7 - Midterm 1\n",
      "Loaded: S7 - Midterm 2\n",
      "Loaded: S9 - Final\n",
      "Loaded: S9 - Midterm 1\n",
      "Loaded: S9 - Midterm 2\n",
      "Shape: (443002, 6)\n",
      "Subjects: ['S5' 'S2' 'S3' 'S4' 'S10' 'S8' 'S1' 'S6' 'S7' 'S9']\n",
      "Sessions: ['Final' 'Midterm 1' 'Midterm 2']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def load_signal(filepath):\n",
    "    df = pd.read_csv(filepath, header=None)\n",
    "    start_time = df.iloc[0, 0]\n",
    "    sample_rate = float(df.iloc[1, 0])\n",
    "    values = df.iloc[2:].reset_index(drop=True).astype(float)\n",
    "    timestamps = pd.to_datetime(start_time, unit='s') + pd.to_timedelta(np.arange(len(values)) / sample_rate, unit='s')\n",
    "    return timestamps, values\n",
    "\n",
    "def load_session(hr_path, eda_path, temp_path, subject_id, session):\n",
    "    hr_times, hr_values = load_signal(hr_path)\n",
    "    eda_times, eda_values = load_signal(eda_path)\n",
    "    temp_times, temp_values = load_signal(temp_path)\n",
    "\n",
    "    min_len = min(len(hr_times), len(eda_times), len(temp_times))\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'timestamp': hr_times[:min_len],\n",
    "        'heart_rate': hr_values.iloc[:min_len, 0],\n",
    "        'eda': eda_values.iloc[:min_len, 0],\n",
    "        'temperature': temp_values.iloc[:min_len, 0],\n",
    "        'subject_id': subject_id,\n",
    "        'session': session\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "base_dir = Path('/Users/hteshome/Desktop/4-it-s-about-time-haile-teshome/Data')\n",
    "\n",
    "all_data = []\n",
    "\n",
    "\n",
    "for subject_folder in base_dir.glob('S*'):\n",
    "    subject_id = subject_folder.name \n",
    "\n",
    "    for session_folder_name in ['Final', 'Midterm 1', 'Midterm 2']:\n",
    "        session_folder = subject_folder / session_folder_name\n",
    "\n",
    "        if session_folder.exists():\n",
    "            try:\n",
    "                hr_path = session_folder / 'HR.csv'\n",
    "                eda_path = session_folder / 'EDA.csv'\n",
    "                temp_path = session_folder / 'TEMP.csv'\n",
    "\n",
    "                session_data = load_session(hr_path, eda_path, temp_path, subject_id, session_folder_name)\n",
    "                all_data.append(session_data)\n",
    "\n",
    "                print(f\"Loaded: {subject_id} - {session_folder_name}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load {subject_id} - {session_folder_name}: {e}\")\n",
    "        else:\n",
    "            print(f\"Missing folder: {session_folder}\")\n",
    "\n",
    "# Combine everything\n",
    "combined_data = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "print(\"Shape:\", combined_data.shape)\n",
    "print(\"Subjects:\", combined_data['subject_id'].unique())\n",
    "print(\"Sessions:\", combined_data['session'].unique())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "Implement the `preprocess_data` function to clean and prepare the data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, output_dir='processed_data'):\n",
    "    \"\"\"\n",
    "    Preprocess physiological data:\n",
    "    - Handle missing values\n",
    "    - Resample to regular intervals\n",
    "    - Remove outliers\n",
    "    - Save processed data per subject\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): Combined raw data\n",
    "        output_dir (str): Directory to save processed files\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Clean processed combined data\n",
    "    \"\"\"\n",
    "    from pathlib import Path\n",
    "    from scipy import stats\n",
    "    import os\n",
    "\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(\"\\nPreprocessing data...\")\n",
    "    processed_subjects = []\n",
    "\n",
    "    data = data.sort_values(by=['subject_id', 'session', 'timestamp'])\n",
    "    data.interpolate(method='linear', inplace=True, limit_direction='forward')\n",
    "    data.fillna(method='ffill', inplace=True)\n",
    "\n",
    "    for col in ['heart_rate', 'eda', 'temperature']:\n",
    "        z_scores = np.abs(stats.zscore(data[col]))\n",
    "        data = data[z_scores < 3.5]\n",
    "\n",
    "    for subject_id, subject_group in data.groupby('subject_id'):\n",
    "        subject_processed = []\n",
    "\n",
    "        for session, session_group in subject_group.groupby('session'):\n",
    "            session_group = session_group.set_index('timestamp').resample('1S').mean(numeric_only=True)\n",
    "            session_group['subject_id'] = subject_id\n",
    "            session_group['session'] = session\n",
    "            subject_processed.append(session_group.reset_index())\n",
    "\n",
    "\n",
    "        subject_df = pd.concat(subject_processed, ignore_index=True)\n",
    "        processed_subjects.append(subject_df)\n",
    "        subject_file = output_dir / f\"{subject_id}_processed.csv\"\n",
    "        subject_df.to_csv(subject_file, index=False)\n",
    "        print(f\"Saved: {subject_file}\")\n",
    "\n",
    "    processed_data = pd.concat(processed_subjects, ignore_index=True)\n",
    "    print(\"\\nPreprocessing complete!\")\n",
    "    print(\"Processed shape:\", processed_data.shape)\n",
    "    return processed_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualization\n",
    "\n",
    "Implement the `plot_physiological_signals` function to create visualizations of the physiological data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "def plot_physiological_signals(data, subject_id, session, output_dir='plots'):\n",
    "    \"\"\"\n",
    "    Plot physiological signals for a given subject and session.\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): Processed data.\n",
    "        subject_id (str): Subject ID (e.g., 'S1').\n",
    "        session (str): Session name ('Final', 'Midterm 1', 'Midterm 2').\n",
    "        output_dir (str): Directory to save plots.\n",
    "        \n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: The plot figure object.\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    subset = data[(data['subject_id'] == subject_id) & (data['session'] == session)]\n",
    "\n",
    "    if subset.empty:\n",
    "        print(f\"No data found for {subject_id} - {session}\")\n",
    "        return None\n",
    "\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "    axs[0].plot(subset['timestamp'], subset['heart_rate'], label='Heart Rate (bpm)')\n",
    "    axs[0].set_ylabel('Heart Rate (bpm)')\n",
    "    axs[0].legend()\n",
    "    axs[0].grid(True)\n",
    "    axs[1].plot(subset['timestamp'], subset['eda'], color='orange', label='EDA (μS)')\n",
    "    axs[1].set_ylabel('EDA (μS)')\n",
    "    axs[1].legend()\n",
    "    axs[1].grid(True)\n",
    "    axs[2].plot(subset['timestamp'], subset['temperature'], color='green', label='Temperature (°C)')\n",
    "    axs[2].set_ylabel('Temperature (°C)')\n",
    "    axs[2].legend()\n",
    "    axs[2].grid(True)\n",
    "    fig.suptitle(f'Physiological Signals - {subject_id} - {session}', fontsize=16)\n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "    plot_filename = output_dir / f\"{subject_id}_{session.replace(' ', '_')}_signals.png\"\n",
    "    fig.savefig(plot_filename)\n",
    "\n",
    "    print(f\"Plot saved to {plot_filename}\")\n",
    "    plt.close(fig)\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
