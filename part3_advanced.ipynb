{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Advanced Analysis\n",
    "\n",
    "In this part, we will implement advanced analysis techniques for physiological time series data, including time-domain feature extraction, frequency analysis, and wavelet transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/318xx77d4wbb95s3dsdtsshc0000gq/T/ipykernel_3526/602292936.py:11: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "import pywt\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn')\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Time-Domain Feature Extraction\n",
    "\n",
    "Implement the `extract_time_domain_features` function to extract various time-domain features from physiological signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time_domain_features(data, window_size=60):\n",
    "    \"\"\"\n",
    "    Extract time-domain features from physiological signals.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas.DataFrame\n",
    "        Input data with columns: ['timestamp', 'heart_rate', 'eda', 'temperature', 'subject_id', 'session']\n",
    "    window_size : int, optional\n",
    "        Size of the rolling window in seconds, default=60\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame containing extracted features for each window\n",
    "    \"\"\"\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "    data = data.sort_values(by=['subject_id', 'session', 'timestamp'])\n",
    "\n",
    "    data = data.set_index('timestamp')\n",
    "    results = []\n",
    "\n",
    "    for (subject_id, session), group in data.groupby(['subject_id', 'session']):\n",
    "        window = f'{window_size}s'\n",
    "\n",
    "        rr_intervals = 60000 / group['heart_rate']\n",
    "        rr_diff = rr_intervals.diff()\n",
    "\n",
    "        features = pd.DataFrame(index=group.index)\n",
    "        features['mean_hr'] = group['heart_rate'].rolling(window).mean()\n",
    "        features['std_hr'] = group['heart_rate'].rolling(window).std()\n",
    "        features['min_hr'] = group['heart_rate'].rolling(window).min()\n",
    "        features['max_hr'] = group['heart_rate'].rolling(window).max()\n",
    "        features['rmssd'] = rr_diff.rolling(window).apply(lambda x: np.sqrt(np.mean(x**2)) if len(x.dropna()) > 1 else np.nan)\n",
    "        features['sdnn'] = rr_intervals.rolling(window).std()\n",
    "        features['pnn50'] = rr_diff.rolling(window).apply(\n",
    "            lambda x: 100 * np.mean(np.abs(x) > 50) if len(x.dropna()) > 1 else np.nan\n",
    "        )\n",
    "\n",
    "        features['mean_eda'] = group['eda'].rolling(window).mean()\n",
    "        features['mean_temp'] = group['temperature'].rolling(window).mean()\n",
    "        features['subject_id'] = subject_id\n",
    "        features['session'] = session\n",
    "        features = features.reset_index()\n",
    "        results.append(features)\n",
    "\n",
    "    return pd.concat(results, ignore_index=True).dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = Path('/Users/hteshome/Desktop/4-it-s-about-time-haile-teshome/processed_data/')\n",
    "# all_files = list(data_dir.glob(\"S*_processed.csv\"))\n",
    "# dataframes = [pd.read_csv(file) for file in all_files]\n",
    "# preprocessed_data = pd.concat(dataframes, ignore_index=True)\n",
    "# preprocessed_data['timestamp'] = pd.to_datetime(preprocessed_data['timestamp'])\n",
    "\n",
    "# time_domain_df = extract_time_domain_features(preprocessed_data, window_size=60)\n",
    "\n",
    "# time_domain_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Frequency Analysis\n",
    "\n",
    "Implement the `analyze_frequency_components` function to perform frequency-domain analysis on the signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_frequency_components(data, sampling_rate=1.0, window_size=60, upsample_to=4.0):\n",
    "    \"\"\"\n",
    "    Perform frequency-domain analysis on heart_rate signal.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas.DataFrame\n",
    "        Input data with columns: ['timestamp', 'heart_rate']\n",
    "    sampling_rate : float\n",
    "        Original sampling rate (Hz)\n",
    "    window_size : int\n",
    "        Window size in seconds\n",
    "    upsample_to : float\n",
    "        Target sampling rate in Hz for interpolation (e.g. 4.0 Hz)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing frequency bands and power spectrum\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "    data = data.sort_values('timestamp')\n",
    "    data = data.set_index('timestamp')\n",
    "    data = data[~data.index.duplicated(keep='first')]\n",
    "    resample_interval = f'{int(1000 / upsample_to)}ms'  \n",
    "    data_interp = data['heart_rate'].resample(resample_interval).interpolate(method='linear')\n",
    "    data_interp = data_interp.dropna()\n",
    "    data_interp = data_interp.to_frame().reset_index()\n",
    "    fs = upsample_to\n",
    "    window_samples = int(window_size * fs)\n",
    "    nyquist = fs / 2\n",
    "    band_limits = {\n",
    "        'VLF': (0.003, min(0.04, nyquist)),\n",
    "        'LF':  (0.04,  min(0.15, nyquist)),\n",
    "        'HF':  (0.15,  min(0.4, nyquist)),\n",
    "    }\n",
    "\n",
    "    results = {\n",
    "        'frequencies': [],\n",
    "        'power': [],\n",
    "        'bands': {'VLF': [], 'LF': [], 'HF': [], 'LF/HF': []}\n",
    "    }\n",
    "\n",
    "    n_windows = len(data_interp) // window_samples\n",
    "\n",
    "    for i in range(n_windows):\n",
    "        window_data = data_interp['heart_rate'].iloc[i * window_samples : (i + 1) * window_samples]\n",
    "        if len(window_data) < window_samples:\n",
    "            continue\n",
    "\n",
    "        freqs, power = signal.welch(window_data, fs=fs, nperseg=window_samples)\n",
    "        results['frequencies'].append(freqs)\n",
    "        results['power'].append(power)\n",
    "\n",
    "        band_power = {}\n",
    "        for band, (low, high) in band_limits.items():\n",
    "            mask = (freqs >= low) & (freqs <= high)\n",
    "            if np.any(mask):\n",
    "                band_power[band] = np.trapz(power[mask], freqs[mask])\n",
    "            else:\n",
    "                band_power[band] = np.nan\n",
    "\n",
    "        lf = band_power['LF']\n",
    "        hf = band_power['HF']\n",
    "        lf_hf = lf / hf if hf and hf > 0 else np.nan\n",
    "\n",
    "        for band in ['VLF', 'LF', 'HF']:\n",
    "            results['bands'][band].append(band_power[band])\n",
    "        results['bands']['LF/HF'].append(lf_hf)\n",
    "\n",
    "    results['frequencies'] = np.nanmean(results['frequencies'], axis=0)\n",
    "    results['power'] = np.nanmean(results['power'], axis=0)\n",
    "    for key in results['bands']:\n",
    "        results['bands'][key] = np.nanmean(results['bands'][key])\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data = preprocessed_data[['timestamp', 'heart_rate']]\n",
    "# freq_results = analyze_frequency_components(input_data)\n",
    "# print(freq_results['bands'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Time-Frequency Analysis\n",
    "\n",
    "Implement the `analyze_time_frequency_features` function to analyze time-frequency features using wavelet transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_time_frequency_features(data, sampling_rate=1.0, window_size=60, upsample_to=4.0):\n",
    "    \"\"\"\n",
    "    Perform time-frequency analysis on heart_rate signal using wavelet transform.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas.DataFrame\n",
    "        Must include ['timestamp', 'heart_rate']\n",
    "    sampling_rate : float\n",
    "        Original sampling rate of input data (Hz)\n",
    "    window_size : int\n",
    "        Length of each analysis window in seconds\n",
    "    upsample_to : float\n",
    "        Target sampling rate in Hz for interpolation (e.g., 4.0 Hz)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing wavelet 'scales', 'frequencies',\n",
    "        averaged 'coefficients', and 'time_frequency_energy'\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "    data = data.sort_values('timestamp')\n",
    "    data = data.set_index('timestamp')\n",
    "    data = data[~data.index.duplicated(keep='first')]\n",
    "\n",
    "    resample_interval = f'{int(1000 / upsample_to)}ms'\n",
    "    heart_rate_interp = data['heart_rate'].resample(resample_interval).interpolate(method='linear')\n",
    "    heart_rate_interp = heart_rate_interp.dropna().to_frame().reset_index()\n",
    "\n",
    "    fs = upsample_to\n",
    "    window_samples = int(window_size * fs)\n",
    "\n",
    "    scales = np.arange(1, 128)\n",
    "    frequencies = pywt.scale2frequency('morl', scales) * fs\n",
    "\n",
    "    results = {\n",
    "        'scales': scales,\n",
    "        'frequencies': frequencies,\n",
    "        'coefficients': None,\n",
    "        'time_frequency_energy': None\n",
    "    }\n",
    "\n",
    "    n_windows = len(heart_rate_interp) // window_samples\n",
    "    all_coeffs = []\n",
    "    all_energy = []\n",
    "\n",
    "    for i in range(n_windows):\n",
    "        window_data = heart_rate_interp['heart_rate'].iloc[i * window_samples : (i + 1) * window_samples]\n",
    "\n",
    "        if window_data.isnull().any() or len(window_data) < window_samples:\n",
    "            continue\n",
    "\n",
    "        coeffs, freqs = pywt.cwt(\n",
    "            window_data,\n",
    "            scales=scales,\n",
    "            wavelet='morl',\n",
    "            sampling_period=1.0 / fs\n",
    "        )\n",
    "        energy = np.abs(coeffs) ** 2\n",
    "\n",
    "        all_coeffs.append(coeffs)\n",
    "        all_energy.append(energy)\n",
    "\n",
    "    if all_coeffs:\n",
    "        results['coefficients'] = np.mean(all_coeffs, axis=0)\n",
    "        results['time_frequency_energy'] = np.mean(all_energy, axis=0)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage\n",
    "\n",
    "Here's how to use these functions with your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('/Users/hteshome/Desktop/4-it-s-about-time-haile-teshome/processed_data/S1_processed.csv')\n",
    "\n",
    "# features = extract_time_domain_features(data, window_size=60)\n",
    "# print(\"Time-domain features:\")\n",
    "# print(features.head())\n",
    "\n",
    "# sampling_rate = 4.0  # Hz\n",
    "# freq_results = analyze_frequency_components(data, sampling_rate, window_size=60)\n",
    "# print(\"\\nFrequency analysis results:\")\n",
    "# print(\"Frequency bands:\", freq_results['bands'])\n",
    "\n",
    "# tf_results = analyze_time_frequency_features(data, sampling_rate, window_size=60)\n",
    "# print(\"\\nTime-frequency analysis results:\")\n",
    "# print(\"Wavelet scales:\", tf_results['scales'].shape)\n",
    "# print(\"Coefficients shape:\", tf_results['coefficients'].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
