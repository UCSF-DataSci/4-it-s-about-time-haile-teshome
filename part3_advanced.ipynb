{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Advanced Analysis\n",
    "\n",
    "In this part, we will implement advanced analysis techniques for physiological time series data, including time-domain feature extraction, frequency analysis, and wavelet transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/318xx77d4wbb95s3dsdtsshc0000gq/T/ipykernel_3526/2679646345.py:9: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "import pywt\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn')\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Time-Domain Feature Extraction\n",
    "\n",
    "Implement the `extract_time_domain_features` function to extract various time-domain features from physiological signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time_domain_features(data, window_size=60):\n",
    "    \"\"\"\n",
    "    Extract time-domain features from physiological signals.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas.DataFrame\n",
    "        Input data with columns: ['timestamp', 'heart_rate', 'eda', 'temperature', 'subject_id', 'session']\n",
    "    window_size : int, optional\n",
    "        Size of the rolling window in seconds, default=60\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame containing extracted features for each window\n",
    "    \"\"\"\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "    data = data.sort_values(by=['subject_id', 'session', 'timestamp'])\n",
    "\n",
    "    data = data.set_index('timestamp')\n",
    "    results = []\n",
    "\n",
    "    for (subject_id, session), group in data.groupby(['subject_id', 'session']):\n",
    "        window = f'{window_size}s'\n",
    "\n",
    "        rr_intervals = 60000 / group['heart_rate']\n",
    "        rr_diff = rr_intervals.diff()\n",
    "\n",
    "        features = pd.DataFrame(index=group.index)\n",
    "        features['mean_hr'] = group['heart_rate'].rolling(window).mean()\n",
    "        features['std_hr'] = group['heart_rate'].rolling(window).std()\n",
    "        features['min_hr'] = group['heart_rate'].rolling(window).min()\n",
    "        features['max_hr'] = group['heart_rate'].rolling(window).max()\n",
    "        features['rmssd'] = rr_diff.rolling(window).apply(lambda x: np.sqrt(np.mean(x**2)) if len(x.dropna()) > 1 else np.nan)\n",
    "        features['sdnn'] = rr_intervals.rolling(window).std()\n",
    "        features['pnn50'] = rr_diff.rolling(window).apply(\n",
    "            lambda x: 100 * np.mean(np.abs(x) > 50) if len(x.dropna()) > 1 else np.nan\n",
    "        )\n",
    "\n",
    "        features['mean_eda'] = group['eda'].rolling(window).mean()\n",
    "        features['mean_temp'] = group['temperature'].rolling(window).mean()\n",
    "        features['subject_id'] = subject_id\n",
    "        features['session'] = session\n",
    "        features = features.reset_index()\n",
    "        results.append(features)\n",
    "\n",
    "    return pd.concat(results, ignore_index=True).dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>mean_hr</th>\n",
       "      <th>std_hr</th>\n",
       "      <th>min_hr</th>\n",
       "      <th>max_hr</th>\n",
       "      <th>rmssd</th>\n",
       "      <th>sdnn</th>\n",
       "      <th>pnn50</th>\n",
       "      <th>mean_eda</th>\n",
       "      <th>mean_temp</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-05 16:29:09</td>\n",
       "      <td>98.276667</td>\n",
       "      <td>16.834626</td>\n",
       "      <td>82.5</td>\n",
       "      <td>116.0</td>\n",
       "      <td>165.854469</td>\n",
       "      <td>105.016249</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>0.008542</td>\n",
       "      <td>21.89</td>\n",
       "      <td>S1</td>\n",
       "      <td>Final</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-05 16:29:10</td>\n",
       "      <td>95.270000</td>\n",
       "      <td>15.003220</td>\n",
       "      <td>82.5</td>\n",
       "      <td>116.0</td>\n",
       "      <td>141.791240</td>\n",
       "      <td>93.228931</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.011852</td>\n",
       "      <td>21.89</td>\n",
       "      <td>S1</td>\n",
       "      <td>Final</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-05 16:29:11</td>\n",
       "      <td>95.936000</td>\n",
       "      <td>13.078235</td>\n",
       "      <td>82.5</td>\n",
       "      <td>116.0</td>\n",
       "      <td>130.294292</td>\n",
       "      <td>82.015672</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.014095</td>\n",
       "      <td>21.89</td>\n",
       "      <td>S1</td>\n",
       "      <td>Final</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-12-05 16:29:12</td>\n",
       "      <td>97.863333</td>\n",
       "      <td>12.614272</td>\n",
       "      <td>82.5</td>\n",
       "      <td>116.0</td>\n",
       "      <td>118.696696</td>\n",
       "      <td>79.675707</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>0.015803</td>\n",
       "      <td>21.89</td>\n",
       "      <td>S1</td>\n",
       "      <td>Final</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-12-05 16:29:13</td>\n",
       "      <td>100.127143</td>\n",
       "      <td>12.979743</td>\n",
       "      <td>82.5</td>\n",
       "      <td>116.0</td>\n",
       "      <td>109.066988</td>\n",
       "      <td>80.940003</td>\n",
       "      <td>71.428571</td>\n",
       "      <td>0.016840</td>\n",
       "      <td>21.89</td>\n",
       "      <td>S1</td>\n",
       "      <td>Final</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp     mean_hr     std_hr  min_hr  max_hr       rmssd  \\\n",
       "2 2018-12-05 16:29:09   98.276667  16.834626    82.5   116.0  165.854469   \n",
       "3 2018-12-05 16:29:10   95.270000  15.003220    82.5   116.0  141.791240   \n",
       "4 2018-12-05 16:29:11   95.936000  13.078235    82.5   116.0  130.294292   \n",
       "5 2018-12-05 16:29:12   97.863333  12.614272    82.5   116.0  118.696696   \n",
       "6 2018-12-05 16:29:13  100.127143  12.979743    82.5   116.0  109.066988   \n",
       "\n",
       "         sdnn      pnn50  mean_eda  mean_temp subject_id session  \n",
       "2  105.016249  66.666667  0.008542      21.89         S1   Final  \n",
       "3   93.228931  75.000000  0.011852      21.89         S1   Final  \n",
       "4   82.015672  80.000000  0.014095      21.89         S1   Final  \n",
       "5   79.675707  83.333333  0.015803      21.89         S1   Final  \n",
       "6   80.940003  71.428571  0.016840      21.89         S1   Final  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_dir = Path('/Users/hteshome/Desktop/4-it-s-about-time-haile-teshome/processed_data/')\n",
    "# all_files = list(data_dir.glob(\"S*_processed.csv\"))\n",
    "# dataframes = [pd.read_csv(file) for file in all_files]\n",
    "# preprocessed_data = pd.concat(dataframes, ignore_index=True)\n",
    "# preprocessed_data['timestamp'] = pd.to_datetime(preprocessed_data['timestamp'])\n",
    "\n",
    "# time_domain_df = extract_time_domain_features(preprocessed_data, window_size=60)\n",
    "\n",
    "# time_domain_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Frequency Analysis\n",
    "\n",
    "Implement the `analyze_frequency_components` function to perform frequency-domain analysis on the signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_frequency_components(data, sampling_rate=1.0, window_size=60, upsample_to=4.0):\n",
    "    \"\"\"\n",
    "    Perform frequency-domain analysis on heart_rate signal.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas.DataFrame\n",
    "        Input data with columns: ['timestamp', 'heart_rate']\n",
    "    sampling_rate : float\n",
    "        Original sampling rate (Hz)\n",
    "    window_size : int\n",
    "        Window size in seconds\n",
    "    upsample_to : float\n",
    "        Target sampling rate in Hz for interpolation (e.g. 4.0 Hz)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing frequency bands and power spectrum\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "    data = data.sort_values('timestamp')\n",
    "    data = data.set_index('timestamp')\n",
    "    data = data[~data.index.duplicated(keep='first')]\n",
    "    resample_interval = f'{int(1000 / upsample_to)}ms'  \n",
    "    data_interp = data['heart_rate'].resample(resample_interval).interpolate(method='linear')\n",
    "    data_interp = data_interp.dropna()\n",
    "    data_interp = data_interp.to_frame().reset_index()\n",
    "    fs = upsample_to\n",
    "    window_samples = int(window_size * fs)\n",
    "    nyquist = fs / 2\n",
    "    band_limits = {\n",
    "        'VLF': (0.003, min(0.04, nyquist)),\n",
    "        'LF':  (0.04,  min(0.15, nyquist)),\n",
    "        'HF':  (0.15,  min(0.4, nyquist)),\n",
    "    }\n",
    "\n",
    "    results = {\n",
    "        'frequencies': [],\n",
    "        'power': [],\n",
    "        'bands': {'VLF': [], 'LF': [], 'HF': [], 'LF/HF': []}\n",
    "    }\n",
    "\n",
    "    n_windows = len(data_interp) // window_samples\n",
    "\n",
    "    for i in range(n_windows):\n",
    "        window_data = data_interp['heart_rate'].iloc[i * window_samples : (i + 1) * window_samples]\n",
    "        if len(window_data) < window_samples:\n",
    "            continue\n",
    "\n",
    "        freqs, power = signal.welch(window_data, fs=fs, nperseg=window_samples)\n",
    "        results['frequencies'].append(freqs)\n",
    "        results['power'].append(power)\n",
    "\n",
    "        band_power = {}\n",
    "        for band, (low, high) in band_limits.items():\n",
    "            mask = (freqs >= low) & (freqs <= high)\n",
    "            if np.any(mask):\n",
    "                band_power[band] = np.trapz(power[mask], freqs[mask])\n",
    "            else:\n",
    "                band_power[band] = np.nan\n",
    "\n",
    "        lf = band_power['LF']\n",
    "        hf = band_power['HF']\n",
    "        lf_hf = lf / hf if hf and hf > 0 else np.nan\n",
    "\n",
    "        for band in ['VLF', 'LF', 'HF']:\n",
    "            results['bands'][band].append(band_power[band])\n",
    "        results['bands']['LF/HF'].append(lf_hf)\n",
    "\n",
    "    results['frequencies'] = np.nanmean(results['frequencies'], axis=0)\n",
    "    results['power'] = np.nanmean(results['power'], axis=0)\n",
    "    for key in results['bands']:\n",
    "        results['bands'][key] = np.nanmean(results['bands'][key])\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'VLF': 0.11884664478920848, 'LF': 0.5785192060174813, 'HF': 0.9334007784251022, 'LF/HF': 350.6605508350544}\n"
     ]
    }
   ],
   "source": [
    "# input_data = preprocessed_data[['timestamp', 'heart_rate']]\n",
    "# freq_results = analyze_frequency_components(input_data)\n",
    "# print(freq_results['bands'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Time-Frequency Analysis\n",
    "\n",
    "Implement the `analyze_time_frequency_features` function to analyze time-frequency features using wavelet transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_time_frequency_features(data, sampling_rate=1.0, window_size=60, upsample_to=4.0):\n",
    "    \"\"\"\n",
    "    Perform time-frequency analysis on heart_rate signal using wavelet transform.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas.DataFrame\n",
    "        Must include ['timestamp', 'heart_rate']\n",
    "    sampling_rate : float\n",
    "        Original sampling rate of input data (Hz)\n",
    "    window_size : int\n",
    "        Length of each analysis window in seconds\n",
    "    upsample_to : float\n",
    "        Target sampling rate in Hz for interpolation (e.g., 4.0 Hz)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing wavelet 'scales', 'frequencies',\n",
    "        averaged 'coefficients', and 'time_frequency_energy'\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "    data = data.sort_values('timestamp')\n",
    "    data = data.set_index('timestamp')\n",
    "    data = data[~data.index.duplicated(keep='first')]\n",
    "\n",
    "    resample_interval = f'{int(1000 / upsample_to)}ms'\n",
    "    heart_rate_interp = data['heart_rate'].resample(resample_interval).interpolate(method='linear')\n",
    "    heart_rate_interp = heart_rate_interp.dropna().to_frame().reset_index()\n",
    "\n",
    "    fs = upsample_to\n",
    "    window_samples = int(window_size * fs)\n",
    "\n",
    "    scales = np.arange(1, 128)\n",
    "    frequencies = pywt.scale2frequency('morl', scales) * fs\n",
    "\n",
    "    results = {\n",
    "        'scales': scales,\n",
    "        'frequencies': frequencies,\n",
    "        'coefficients': None,\n",
    "        'time_frequency_energy': None\n",
    "    }\n",
    "\n",
    "    n_windows = len(heart_rate_interp) // window_samples\n",
    "    all_coeffs = []\n",
    "    all_energy = []\n",
    "\n",
    "    for i in range(n_windows):\n",
    "        window_data = heart_rate_interp['heart_rate'].iloc[i * window_samples : (i + 1) * window_samples]\n",
    "\n",
    "        if window_data.isnull().any() or len(window_data) < window_samples:\n",
    "            continue\n",
    "\n",
    "        coeffs, freqs = pywt.cwt(\n",
    "            window_data,\n",
    "            scales=scales,\n",
    "            wavelet='morl',\n",
    "            sampling_period=1.0 / fs\n",
    "        )\n",
    "        energy = np.abs(coeffs) ** 2\n",
    "\n",
    "        all_coeffs.append(coeffs)\n",
    "        all_energy.append(energy)\n",
    "\n",
    "    if all_coeffs:\n",
    "        results['coefficients'] = np.mean(all_coeffs, axis=0)\n",
    "        results['time_frequency_energy'] = np.mean(all_energy, axis=0)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage\n",
    "\n",
    "Here's how to use these functions with your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-domain features:\n",
      "            timestamp     mean_hr     std_hr  min_hr  max_hr       rmssd  \\\n",
      "2 2018-12-05 16:29:09   98.276667  16.834626    82.5   116.0  165.854469   \n",
      "3 2018-12-05 16:29:10   95.270000  15.003220    82.5   116.0  141.791240   \n",
      "4 2018-12-05 16:29:11   95.936000  13.078235    82.5   116.0  130.294292   \n",
      "5 2018-12-05 16:29:12   97.863333  12.614272    82.5   116.0  118.696696   \n",
      "6 2018-12-05 16:29:13  100.127143  12.979743    82.5   116.0  109.066988   \n",
      "\n",
      "         sdnn      pnn50  mean_eda  mean_temp subject_id session  \n",
      "2  105.016249  66.666667  0.008542      21.89         S1   Final  \n",
      "3   93.228931  75.000000  0.011852      21.89         S1   Final  \n",
      "4   82.015672  80.000000  0.014095      21.89         S1   Final  \n",
      "5   79.675707  83.333333  0.015803      21.89         S1   Final  \n",
      "6   80.940003  71.428571  0.016840      21.89         S1   Final  \n",
      "\n",
      "Frequency analysis results:\n",
      "Frequency bands: {'VLF': 0.054824789504861096, 'LF': 0.0015452113544484828, 'HF': 0.0001056760958689922, 'LF/HF': 351.81704220637954}\n",
      "\n",
      "Time-frequency analysis results:\n",
      "Wavelet scales: (127,)\n",
      "Coefficients shape: (127, 240)\n"
     ]
    }
   ],
   "source": [
    "# data = pd.read_csv('/Users/hteshome/Desktop/4-it-s-about-time-haile-teshome/processed_data/S1_processed.csv')\n",
    "\n",
    "# features = extract_time_domain_features(data, window_size=60)\n",
    "# print(\"Time-domain features:\")\n",
    "# print(features.head())\n",
    "\n",
    "# sampling_rate = 4.0  # Hz\n",
    "# freq_results = analyze_frequency_components(data, sampling_rate, window_size=60)\n",
    "# print(\"\\nFrequency analysis results:\")\n",
    "# print(\"Frequency bands:\", freq_results['bands'])\n",
    "\n",
    "# tf_results = analyze_time_frequency_features(data, sampling_rate, window_size=60)\n",
    "# print(\"\\nTime-frequency analysis results:\")\n",
    "# print(\"Wavelet scales:\", tf_results['scales'].shape)\n",
    "# print(\"Coefficients shape:\", tf_results['coefficients'].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
